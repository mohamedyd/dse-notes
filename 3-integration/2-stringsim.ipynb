{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Matching\n",
    "The treatment of string attributes in a database requires further discussion. For string attributes,\n",
    "databases are good at looking up or joining on exact matches using hashing. For more complicated\n",
    "conditions (e.g., find all near matches in two tables), this story is a little more complicated. We start\n",
    "our study of string-searching algorithms, sometimes called string-matching algorithms. These are\n",
    "an important class of string algorithms that try to find a place where one or several strings (also\n",
    "called patterns) are found within a larger set of strings.\n",
    "\n",
    "## Similarity Metric\n",
    "A similarity metric is a function that assigns a score to two strings to evaluate how similar they are. For example, the string \"University of Chicago\" and \"Chicago\" should be more similar than \"Apple\" and \"Bannana\". String comparison is a core primitive in data science because having consistent representations is important for programming. \n",
    "\n",
    "One way to design a similarity metric is to consider the tokens in a string. The first step in designing a good string similarity metric is the process of tokenization. This considers the minimum granularity of matching that we will consider. Formally, tokenization takes the string which is a sequence of characters and turns it into a set of tokens. Think of these like the important features of a string that are worth considering. For example, we might tokenize a string on word boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown', 'fox', 'quick', 'the'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = 'the quick brown fox'\n",
    "set(st.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we might tokenize on pairs of sucessive words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('brown', 'fox'), ('quick', 'brown'), ('the', 'quick')}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = 'the quick brown fox'\n",
    "words = st.split()\n",
    "set(zip(words[:-1], words[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our similarity metric will compare how many tokens are shared between two strings. \n",
    "\n",
    "## Jaccard Similarity\n",
    "Over a sequence of tokens one of the simplest (but ubiquitous!) similarity measures is Jaccard\n",
    "Similarity. Jaccard similarity, also known as Intersection over Union, is defined as the size of the\n",
    "intersection (how many unique tokens appear in both) divided by the size of the union (how many\n",
    "unique tokens appear in either). This results in a metric from 0 to 1 where 0 indicates no overlapping tokens and 1 indicates all of the tokens overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(st):\n",
    "    return set(st.lower().split())\n",
    "\n",
    "def jaccard(a,b):\n",
    "    Ta = tokenize(a)\n",
    "    Tb = tokenize(b)\n",
    "    \n",
    "    return len(Ta.intersection(Tb))/len(Ta.union(Tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard('Apple', 'Apple Pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard('Apple Pie', 'Pie Apple Pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard('Banana', 'Apple Pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build a matcher that considers Jaccard Similarities and identifies similar strings in two lists, namely, find all pairs that are within a specific similarity of each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J>=1 [('kermit surprise', 'kermit surprise')]\n",
      "J>=0.5 [('the big bear', 'big bear'), ('alphabet soup', 'alphabet soup 1'), ('kermit surprise', 'kermit surprise')]\n",
      "J>=0.0 [('the big bear', 'big bear'), ('the big bear', 'dogs'), ('the big bear', 'alphabet soup 1'), ('the big bear', 'kermit surprise'), ('dog in the woods', 'big bear'), ('dog in the woods', 'dogs'), ('dog in the woods', 'alphabet soup 1'), ('dog in the woods', 'kermit surprise'), ('alphabet soup', 'big bear'), ('alphabet soup', 'dogs'), ('alphabet soup', 'alphabet soup 1'), ('alphabet soup', 'kermit surprise'), ('kermit surprise', 'big bear'), ('kermit surprise', 'dogs'), ('kermit surprise', 'alphabet soup 1'), ('kermit surprise', 'kermit surprise')]\n"
     ]
    }
   ],
   "source": [
    "strlist1 = [ 'the big bear' , 'dog in the woods' , 'alphabet soup' , 'kermit surprise' ]\n",
    "strlist2 = ['big bear', 'dogs', 'alphabet soup 1', 'kermit surprise' ]\n",
    "\n",
    "\n",
    "def match(l1, l2, threshold):\n",
    "    matches = []\n",
    "    \n",
    "    for i in l1:\n",
    "        for j in l2:\n",
    "            if jaccard(i,j) >= threshold:\n",
    "                matches.append((i,j))\n",
    "    return matches\n",
    "\n",
    "print('J>=1', match(strlist1, strlist2, 1.0))\n",
    "print('J>=0.5', match(strlist1, strlist2, 0.5))\n",
    "print('J>=0.0', match(strlist1, strlist2, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min Hash Algorithm\n",
    "\n",
    "We will now consider an approximate Jaccard matcher which is significantly faster. The MinHash algorithm relies on the fact that the Jaccard Similarity is sort of like a probability---if I randomly draw an element from the union, what is the probability that it will be in the intersection? We can use this insight to develop a fast approximate algorithm. The first thing that we will need is a generator that can generate k independent hash functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "import random\n",
    "\n",
    "def doHash(st, a,b):\n",
    "    NEXTPRIME = 4294967311\n",
    "    val = binascii . crc32( bytes ( str (st), 'utf-8' ))\n",
    "    return (a * val + b) % NEXTPRIME\n",
    "\n",
    "def generateHash(k):\n",
    "    MAXINT = 2**32 - 1\n",
    "    return [ (random.randint(0,MAXINT), random.randint(0,MAXINT)) for i in range(k)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each hash function, we compute the minimum value of the hash function over all possible tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1771224429, 2573226673, 3443466068, 2394302545, 1944151189, 330307586, 380011922, 1691827482, 150724341, 1166715779]\n",
      "[1052982803, 2435591847, 3426789228, 735019560, 1944151189, 330307586, 380011922, 404624650, 150724341, 1166715779]\n",
      "[2037520169, 1042073495, 2726826241, 321601117, 979332860, 3750545969, 208957705, 1042412753, 3372274495, 950563002]\n"
     ]
    }
   ],
   "source": [
    "def minhash(st, a,b):\n",
    "    tokens = tokenize(st)\n",
    "    return min([doHash(t, a, b) for t in tokens])\n",
    "\n",
    "def signature(st, hashes):\n",
    "    return [minhash(st,a,b) for a,b in hashes]\n",
    "\n",
    "hashes = generateHash(10)\n",
    "\n",
    "print(signature('kermit surprise', hashes))\n",
    "print(signature('kermit surprise 1', hashes))\n",
    "print(signature('bear brown', hashes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the results carefully the strings that have a greater overlap have a higher probability of minhashes matching for randomly chosen hash functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance\n",
    "\n",
    "Jaccard similarity is a pretty naive metricâ€“it does not consider the order of words and it does not\n",
    "do well with spelling errors. However, it admits an O(n) time approximation algorithm. In this\n",
    "lecture, we will consider the opposite extreme. A much more comprehesive string similarity met-\n",
    "ric but one that is much harder to compute. \n",
    "\n",
    "### Levenshtein (Edit) Distance\n",
    "The Levenshtein distance is a string metric for measuring the difference between two sequences.\n",
    "Informally, the Levenshtein distance between two words is the minimum number of single-\n",
    "character edits (insertions, deletions or substitutions) required to change one word into the other.\n",
    "Let see a few examples that have an edit distance of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs = ('abc', 'ab') #delete c\n",
    "strs = ('abc','abd') #substitute c for d\n",
    "strs = ('abc', 'abdc') #insert d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more complicated example is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs = ('bac', 'abd') #the edit distance is 3 (insert b, delete b, subtitute c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a simple recursive algorithm to compute edit distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit(s,t):\n",
    "    \n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    \n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    \n",
    "    return min([1 + edit(s[1:], t), \\\n",
    "                1 + edit(s, t[1:]), \\\n",
    "                (s[ 0 ] != t[ 0 ]) + edit(s[ 1 :], t[ 1 :])])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit('kitten', 'sitting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit('kittens the', 'sitting on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing bac abd\n",
      "Comparing ac abd\n",
      "Comparing c abd\n",
      "Comparing  abd\n",
      "Comparing c bd\n",
      "Comparing  bd\n",
      "Comparing c d\n",
      "Comparing  d\n",
      "Comparing c \n",
      "Comparing  \n",
      "Comparing  d\n",
      "Comparing  bd\n",
      "Comparing ac bd\n",
      "Comparing c bd\n",
      "Comparing  bd\n",
      "Comparing c d\n",
      "Comparing  d\n",
      "Comparing c \n",
      "Comparing  \n",
      "Comparing  d\n",
      "Comparing ac d\n",
      "Comparing c d\n",
      "Comparing  d\n",
      "Comparing c \n",
      "Comparing  \n",
      "Comparing ac \n",
      "Comparing c \n",
      "Comparing c d\n",
      "Comparing  d\n",
      "Comparing c \n",
      "Comparing  \n",
      "Comparing c bd\n",
      "Comparing  bd\n",
      "Comparing c d\n",
      "Comparing  d\n",
      "Comparing c \n",
      "Comparing  \n",
      "Comparing  d\n",
      "Comparing bac bd\n",
      "Comparing ac bd\n",
      "Comparing c bd\n",
      "Comparing  bd\n",
      "Comparing c d\n",
      "Comparing  d\n",
      "Comparing c \n",
      "Comparing  \n",
      "Comparing  d\n",
      "Comparing ac d\n",
      "Comparing c d\n",
      "Comparing  d\n",
      "Comparing c \n",
      "Comparing  \n",
      "Comparing ac \n",
      "Comparing c \n",
      "Comparing c d\n",
      "Comparing  d\n",
      "Comparing c \n",
      "Comparing  \n",
      "Comparing bac d\n",
      "Comparing ac d\n",
      "Comparing c d\n",
      "Comparing  d\n",
      "Comparing c \n",
      "Comparing  \n",
      "Comparing ac \n",
      "Comparing c \n",
      "Comparing bac \n",
      "Comparing ac \n",
      "Comparing ac d\n",
      "Comparing c d\n",
      "Comparing  d\n",
      "Comparing c \n",
      "Comparing  \n",
      "Comparing ac \n",
      "Comparing c \n",
      "Comparing ac bd\n",
      "Comparing c bd\n",
      "Comparing  bd\n",
      "Comparing c d\n",
      "Comparing  d\n",
      "Comparing c \n",
      "Comparing  \n",
      "Comparing  d\n",
      "Comparing ac d\n",
      "Comparing c d\n",
      "Comparing  d\n",
      "Comparing c \n",
      "Comparing  \n",
      "Comparing ac \n",
      "Comparing c \n",
      "Comparing c d\n",
      "Comparing  d\n",
      "Comparing c \n",
      "Comparing  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def editp(s,t):\n",
    "    \n",
    "    print('Comparing', s,t)\n",
    "    \n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    \n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    \n",
    "    return min([1 + editp(s[1:], t), 1 + editp(s, t[1:]), (s[ 0 ] != t[ 0 ]) + editp(s[ 1 :], t[ 1 :])])\n",
    "\n",
    "editp('bac', 'abd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memoization = {}\n",
    "\n",
    "def editfast(s,t):\n",
    "    \n",
    "    if (s,t) in memoization:\n",
    "        return memoization[(s,t)]\n",
    "    \n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    \n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    \n",
    "    rtn = min([1 + editfast(s[1:], t), 1 + editfast(s, t[1:]), (s[ 0 ] != t[ 0 ]) + editfast(s[ 1 :], t[ 1 :])])\n",
    "    \n",
    "    memoization[(s,t)] = rtn\n",
    "    \n",
    "    return rtn\n",
    "\n",
    "editfast('kittens the', 'sitting on test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
