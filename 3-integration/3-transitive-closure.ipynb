{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Similarity III\n",
    "Now, we will put the last few lectures together to study a concept called \"Entity Resolution\". Entity Resolution is the task of disambiguating data representations of real world entities in various records or mentions by linking and grouping. For example, there could be different ways of addressing the same person in text, different addresses for businesses, or photos of a particular object. For example, all of these strings represent the same country:\n",
    "\n",
    "```\n",
    "USA\n",
    "U.S.A\n",
    "United States\n",
    "United States of America\n",
    "```\n",
    "\n",
    "Given a list of strings where there might be duplications, we must resolve each duplicate representation to a single canonical representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Metrics\n",
    "Suppose, we use the matchers from the previous lecture to compare the group these strings what goes wrong? There are a couple things that we need to decide. First, when we get a match of two strings $a$ and $b$, how should we pick which one to merge to? But, there is also a more subtle issue. In general, similarity measures are not *transitive*. A metric is transitive if $a \\approx b$ and $b \\approx c$ then $a \\approx c$. \n",
    "\n",
    "Let's try a first pass at this. Let's suppose we prefer the \"shorter\" string. How could we get around this transitivity issue? One solution, is to repeatedly merge pairs of strings until it reaches a \"fixed point\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enuerate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d35bd23268be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mstrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'USA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'US'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'U.S.A'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'China'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Chia'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Belize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecurseMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-d35bd23268be>\u001b[0m in \u001b[0;36mrecurseMerge\u001b[0;34m(strlist)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecurseMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mchanges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmergeone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mchanges\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-d35bd23268be>\u001b[0m in \u001b[0;36mmergeone\u001b[0;34m(strlist)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menuerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0meditSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'enuerate' is not defined"
     ]
    }
   ],
   "source": [
    "import distance \n",
    "import copy\n",
    "\n",
    "#normalize the distance between 0 and 1\n",
    "def editSimilarity(s,t):\n",
    "    return 1 - distance.levenshtein(s,t)/max(len(s), len(t))\n",
    "\n",
    "\n",
    "def mergeone(strlist):\n",
    "    changes = 0\n",
    "    \n",
    "    for i,s in enumerate(strlist):\n",
    "        for j,t in enumerate(strlist):\n",
    "            if s != t and editSimilarity(s,t) >= thresh:\n",
    "                if len(s) < len(j):\n",
    "                    strlist[i] = t\n",
    "                    changes += 1\n",
    "    return changes, strlist\n",
    "\n",
    "\n",
    "def recurseMerge(strlist):\n",
    "    changes, strlist = mergeone(strlist)\n",
    "    \n",
    "    while changes != 0:\n",
    "        changes, strlist = mergeone(strlist)\n",
    "    \n",
    "    return strlist\n",
    "   \n",
    "strlist = ['USA', 'US', 'U.S.A', 'China','Chia', 'Belize']\n",
    "print(recurseMerge(strlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distance \n",
    "\n",
    "#normalize the distance between 0 and 1\n",
    "def editSimilarity(s,t):\n",
    "    return 1 - distance.levenshtein(s,t)/max(len(s), len(t))\n",
    "\n",
    "#build a graph of strings\n",
    "def build_graph(strlist, thresh):\n",
    "    graph = {}\n",
    "    for s in set(strlist):\n",
    "        graph[s] = set()\n",
    "        for t in set(strlist):\n",
    "            if s != t and editSimilarity(s,t) >= thresh:\n",
    "                graph[s].add(t)\n",
    "    return graph    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this code pay close attentions to U.S.A and US:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Belize': set(), 'US': {'USA'}, 'USA': {'US', 'U.S.A'}, 'China': {'Chia'}, 'Chia': {'China'}, 'U.S.A': {'USA'}}\n"
     ]
    }
   ],
   "source": [
    "strlist = ['USA', 'US', 'U.S.A', 'China','Chia', 'Belize']\n",
    "print(build_graph(strlist, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the transitive closure algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Belize'], ['US', 'USA', 'U.S.A'], ['China', 'Chia']]\n"
     ]
    }
   ],
   "source": [
    "def transitive_closure(graph):\n",
    "    \n",
    "    #maintain nodes already found in a cc\n",
    "    already_seen = set()\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    #iterate through each node in the graph\n",
    "    for node in graph:\n",
    "        \n",
    "        #if you haven't seen it before\n",
    "        if node not in already_seen:\n",
    "            \n",
    "            #find all nodes connected\n",
    "            connected_group, already_seen = get_connected_group(node, already_seen, graph)\n",
    "            result.append(connected_group)\n",
    "            \n",
    "    return result\n",
    "\n",
    "\n",
    "#the main thing you have to do\n",
    "def get_connected_group(node, already_seen, graph):\n",
    "        result = []\n",
    "        \n",
    "        #start with yourself, a list of things to expand\n",
    "        nodes = set([node])\n",
    "        \n",
    "        #while you still have stuff to expand\n",
    "        while nodes:\n",
    "            \n",
    "            #expand from the top of the expansion set\n",
    "            node = nodes.pop()\n",
    "            already_seen.add(node)\n",
    "            \n",
    "            #connect your self to everyone neighboring you haven't already seend\n",
    "            nodes = nodes or (graph[node] - already_seen)\n",
    "            \n",
    "            #add to result\n",
    "            result.append(node)\n",
    "        return result, already_seen\n",
    "    \n",
    "\n",
    "print(transitive_closure(build_graph(strlist, 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
